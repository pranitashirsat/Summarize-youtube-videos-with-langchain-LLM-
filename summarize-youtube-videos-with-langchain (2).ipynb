{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30498,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About\n\n- Use Langchain to create a summary of an youtube video (in english)\n- Use [Falcon](https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2) (fully open source chat model)","metadata":{}},{"cell_type":"code","source":"import os\nos._exit(00)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:35:57.127099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n! pip install -qq -U langchain youtube_transcript_api einops\n! pip install -qq -U accelerate bitsandbytes xformers","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:41:27.456626Z","iopub.execute_input":"2024-08-30T22:41:27.457009Z","iopub.status.idle":"2024-08-30T22:41:51.851144Z","shell.execute_reply.started":"2024-08-30T22:41:27.456974Z","shell.execute_reply":"2024-08-30T22:41:51.849988Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"CPU times: user 327 ms, sys: 86.4 ms, total: 413 ms\nWall time: 24.4 s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Installs & Imports","metadata":{}},{"cell_type":"code","source":"\n!pip install torch torchvision --force-reinstall","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:55:25.962297Z","iopub.execute_input":"2024-08-30T22:55:25.963285Z","iopub.status.idle":"2024-08-30T22:57:48.886305Z","shell.execute_reply.started":"2024-08-30T22:55:25.963245Z","shell.execute_reply":"2024-08-30T22:57:48.885228Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Collecting torch\n  Using cached torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\nCollecting torchvision\n  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting filelock (from torch)\n  Downloading filelock-3.15.4-py3-none-any.whl (16 kB)\nCollecting typing-extensions>=4.8.0 (from torch)\n  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nCollecting sympy (from torch)\n  Downloading sympy-1.13.2-py3-none-any.whl (6.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting networkx (from torch)\n  Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting jinja2 (from torch)\n  Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting fsspec (from torch)\n  Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\nCollecting nvidia-nccl-cu12==2.20.5 (from torch)\n  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\nCollecting triton==3.0.0 (from torch)\n  Using cached triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n  Using cached nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\nCollecting numpy (from torchvision)\n  Downloading numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting MarkupSafe>=2.0 (from jinja2->torch)\n  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision\n  Attempting uninstall: mpmath\n    Found existing installation: mpmath 1.3.0\n    Uninstalling mpmath-1.3.0:\n      Successfully uninstalled mpmath-1.3.0\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.12.2\n    Uninstalling typing_extensions-4.12.2:\n      Successfully uninstalled typing_extensions-4.12.2\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.12\n    Uninstalling sympy-1.12:\n      Successfully uninstalled sympy-1.12\n  Attempting uninstall: pillow\n    Found existing installation: Pillow 9.5.0\n    Uninstalling Pillow-9.5.0:\n      Successfully uninstalled Pillow-9.5.0\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.1.105\n    Uninstalling nvidia-nvtx-cu12-12.1.105:\n      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.68\n    Uninstalling nvidia-nvjitlink-cu12-12.6.68:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.68\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.20.5\n    Uninstalling nvidia-nccl-cu12-2.20.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.2.106\n    Uninstalling nvidia-curand-cu12-10.3.2.106:\n      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Uninstalling numpy-1.23.5:\n      Successfully uninstalled numpy-1.23.5\n  Attempting uninstall: networkx\n    Found existing installation: networkx 3.1\n    Uninstalling networkx-3.1:\n      Successfully uninstalled networkx-3.1\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 2.1.2\n    Uninstalling MarkupSafe-2.1.2:\n      Successfully uninstalled MarkupSafe-2.1.2\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.5.0\n    Uninstalling fsspec-2023.5.0:\n      Successfully uninstalled fsspec-2023.5.0\n  Attempting uninstall: filelock\n    Found existing installation: filelock 3.12.0\n    Uninstalling filelock-3.12.0:\n      Successfully uninstalled filelock-3.12.0\n  Attempting uninstall: triton\n    Found existing installation: triton 3.0.0\n    Uninstalling triton-3.0.0:\n      Successfully uninstalled triton-3.0.0\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n  Attempting uninstall: jinja2\n    Found existing installation: Jinja2 3.1.2\n    Uninstalling Jinja2-3.1.2:\n      Successfully uninstalled Jinja2-3.1.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.15.1\n    Uninstalling torchvision-0.15.1:\n      Successfully uninstalled torchvision-0.15.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.4.1 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\ncuml 23.4.1 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\ndask-cudf 23.4.1 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\naccelerate 0.33.0 requires numpy<2.0.0,>=1.17, but you have numpy 2.1.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 2.1.0 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 10.0.1 which is incompatible.\nbeatrix-jupyterlab 2023.58.190319 requires jupyter-server~=1.16, but you have jupyter-server 2.5.0 which is incompatible.\nbqplot 0.12.39 requires numpy<2.0.0,>=1.10.4, but you have numpy 2.1.0 which is incompatible.\ncudf 23.4.1 requires protobuf<4.22,>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.4.1 requires dask==2023.3.2, but you have dask 2023.5.0 which is incompatible.\ncupy 11.6.0 requires numpy<1.27,>=1.20, but you have numpy 2.1.0 which is incompatible.\ndask-cuda 23.4.0 requires dask==2023.3.2, but you have dask 2023.5.0 which is incompatible.\ndask-cudf 23.4.1 requires dask==2023.3.2, but you have dask 2023.5.0 which is incompatible.\ndistributed 2023.3.2.1 requires dask==2023.3.2, but you have dask 2023.5.0 which is incompatible.\nfastai 2.7.12 requires torch<2.1,>=1.7, but you have torch 2.4.0 which is incompatible.\ngcsfs 2023.5.0 requires fsspec==2023.5.0, but you have fsspec 2024.6.1 which is incompatible.\nibis-framework 5.1.0 requires numpy<2,>=1, but you have numpy 2.1.0 which is incompatible.\njupyterlab-lsp 4.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlangchain 0.2.15 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.0 which is incompatible.\nlangchain-community 0.2.14 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.1.0 which is incompatible.\nmomepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nnumba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 2.1.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 2.1.0 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.10.1 which is incompatible.\nraft-dask 23.4.1 requires dask==2023.3.2, but you have dask 2023.5.0 which is incompatible.\ns3fs 2023.5.0 requires fsspec==2023.5.0, but you have fsspec 2024.6.1 which is incompatible.\nscipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.1.0 which is incompatible.\ntensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 2.1.0 which is incompatible.\ntensorflow-transform 0.14.0 requires numpy<2,>=1.16, but you have numpy 2.1.0 which is incompatible.\ntorchdata 0.6.0 requires torch==2.0.0, but you have torch 2.4.0 which is incompatible.\nydata-profiling 4.1.2 requires numpy<1.24,>=1.16.0, but you have numpy 2.1.0 which is incompatible.\nydata-profiling 4.1.2 requires scipy<1.10,>=1.4.1, but you have scipy 1.10.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed MarkupSafe-2.1.2 filelock-3.15.4 fsspec-2024.6.1 jinja2-3.1.2 mpmath-1.3.0 networkx-3.3 numpy-2.1.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 pillow-10.4.0 sympy-1.13.2 torch-2.4.0 torchvision-0.19.0 triton-3.0.0 typing-extensions-4.12.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import YouTubeVideo\n\nfrom langchain.document_loaders import YoutubeLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.chains import LLMChain\nfrom langchain.chains.summarize import load_summarize_chain\nfrom langchain.llms import HuggingFacePipeline\n\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n\nimport torch\n\nimport langchain\nprint(langchain.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:59:02.439510Z","iopub.execute_input":"2024-08-30T22:59:02.439911Z","iopub.status.idle":"2024-08-30T22:59:02.447017Z","shell.execute_reply.started":"2024-08-30T22:59:02.439868Z","shell.execute_reply":"2024-08-30T22:59:02.445934Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"0.2.15\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Video\n\n- Provide the ID of the video\n- Just visualize the video in the notebook","metadata":{}},{"cell_type":"code","source":"YouTubeVideo('Y_O-x-itHaU', width=700, height=500)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:59:09.866574Z","iopub.execute_input":"2024-08-30T22:59:09.867569Z","iopub.status.idle":"2024-08-30T22:59:09.921152Z","shell.execute_reply.started":"2024-08-30T22:59:09.867530Z","shell.execute_reply":"2024-08-30T22:59:09.920144Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<IPython.lib.display.YouTubeVideo at 0x79f6be13dc30>","text/html":"\n        <iframe\n            width=\"700\"\n            height=\"500\"\n            src=\"https://www.youtube.com/embed/Y_O-x-itHaU\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ","image/jpeg":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"# Load video\n\nWith Langchain","metadata":{}},{"cell_type":"code","source":"loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=Y_O-x-itHaU\")\ntranscript = loader.load()","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:59:14.385691Z","iopub.execute_input":"2024-08-30T22:59:14.386087Z","iopub.status.idle":"2024-08-30T22:59:14.987777Z","shell.execute_reply.started":"2024-08-30T22:59:14.386058Z","shell.execute_reply":"2024-08-30T22:59:14.986933Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"transcript","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:59:19.082636Z","iopub.execute_input":"2024-08-30T22:59:19.083835Z","iopub.status.idle":"2024-08-30T22:59:19.090169Z","shell.execute_reply.started":"2024-08-30T22:59:19.083785Z","shell.execute_reply":"2024-08-30T22:59:19.089180Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[Document(metadata={'source': 'Y_O-x-itHaU'}, page_content=\"land chain is one of the hottest AI Frameworks right now with over 40 000 stars on GitHub as of this video let me help you understand some of the most important aspects of Lang chain and why it's such an amazing library to work with most of us have used chat GPT and are quite fascinated by its capabilities so you can add something like write in this style of Shakespeare how to cook pasta so what happens behind the scenes is that it takes your input and sends it to an AI system as a prompt and that generates a response which is provided back to you and often these systems are called large language models which are trained on a huge amount of text Data from the internet now I want you to imagine a scenario where you are an instructor and you want your students to use chat GPT and submit all of their assignments in the written style of Shakespeare so you can imagine that most of our students are prompting chat GPT to write in this style of Shakespeare and this is quite a waste of time due to the repetition of the same prompt by so many people so to help out our students we decide to build a chat GPT Style app which has a base prompt to write in this style of Shakespeare and it combines that with the user input and since all of that combined together as a prompt to the large language model and gets a response back this technique of combining user input with a base prompt can be easily achieved in langtain using a concept called prompt template prompt templates are quite powerful in a sense that you can give specific instructions to an llm as how to behave or how to respond to the prompt you can say something like you are a helpful assistant or you are an expert in the area these will change the response back from llm drastically now our application is working great we just want to add the capability where we could call any of the available LMS Lang chain makes this very easy where we could swap out any of the llms listed under the model section you might have noticed that there are a few steps happening here where we take the prompt template and provide the user input to it and then specify the L M before we make a call to the llm for the response lag chain makes it easy where we can link all of these components together by something called chain chains are core building blocks of land chain which can help us achieve a specific task by linking multiple components together there are many different types of chains available in Lang chain and these chains are often named after the tasks they perform in our earlier example we wanted to call an llm the chain for that is llm chain if we would like to perform math problems the chain for that is nlm math chain and if we were to perform SQL operations the chain for that is called SQL database chain and if we were to retrieve an answer the chain for that is retrieval QA chain these are some of the many available chains in the langchain library now question answering chains have a special place in the link chain Library so I would like to expand on this a little more let's go back to our example where now we want our students to use chat GPT to answer questions or search from entire books so if they were to copy the text from these books and paste in chat GPT most likely they'll get an error like this which says that it was too long for chat GPT to process and give answer now the way we can overcome this is using Lang chain in Lang chain the typical q a process starts with first loading the document with something called document loaders which helps us extract the text from Source documents and there are a number of document loaders available in Lang chain which support a variety of document formats now once the text is available to us we need to split that text using something called text Splitters which takes the long pieces of text and convert it into small chunks now the next step is to take these chunks of text and convert it to numbers using something called embedding models the way these embedding models work is that they take the text and assign it a number based on their meaning so words and sentences which are similar in meaning are closer to each other in the numbers that are assigned the next step is to store these numbers in a storage called Vector stores or vector databases so that we can later retrieve him now this completes the embedding path or indexing of these documents the retrieval process starts with Vector stores where we have a number of vectors available now to help us understand visually let's imagine these vectors are in two Dimensions with X and Y component which we can plot on an X Y plot in a way that similar meaning vectors are closer in proximity on this X Y axis now once a user asks a question then that question is also embedded in a similar Dimension and then compared against the vectors available to us and there are a number of ways we can retrieve these vectors one of the most common ones is to do a similarity based search where we select the nearest neighbors to our question and retrieve those vectors and convert them to original text form and then generate our response based on those text pieces so essentially now we can take any of the document and store it in Vector stores and when we get a question we can retrieve the answer and then generate a response which means that our students can now search through entire books and get response back from our chat application using the retrieval QA chain now what if we want our chat application to not just search entire books but also perform SQL operations as well as search internet and a few additional tasks the way we can achieve this in langchain is using one of the most exciting features that is Agents language and agents are assistants who have access to tools and can perform tasks using those tools and these agents could be communicated using similar chat interface where if we were to ask him question from the book they know which tool to use and in this case to use the retrieval QA chain and if it were a question about SQL operation then they know to use that particular chain there are a number of agents and there are multiple tools available for these agents in the langchin library you can search internet you can access shell you can also access the thousands of tools available in zapier as well as you can run python function not just that you can use chains as tools as well as custom functions and also other agents as tools now what if we want our agents to remember our conversations for that there is something called memory in Lang chain and there are many different types of memories that can be configured to run with either agents or chains and it helps them remember our conversations in either short term or long term and can be accessed by our application as needed and what if we want our application to generate a response in a way that we could use it Downstream so maybe we want in a Json format or we want in a particular format to do that there is something called output parsers output parsers make sure that the response from the nlm is in a certain format which could be then used Downstream with that we covered an overview of some of the most important features in langtune library and if you'd like to learn in depth on these topics please check my upcoming course at buildbyu.com where we're going to build AI apps using lag chain and understand langchain library in details also if you are a business or an organization and you would like for us to build your land chain applications reach out to us at Menlo parklab.com and of course don't forget to like And subscribe thank you\")]"},"metadata":{}}]},{"cell_type":"markdown","source":"# Splitter","metadata":{}},{"cell_type":"code","source":"text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=50)\ntexts = text_splitter.split_documents(transcript)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:59:27.955484Z","iopub.execute_input":"2024-08-30T22:59:27.955830Z","iopub.status.idle":"2024-08-30T22:59:27.966217Z","shell.execute_reply.started":"2024-08-30T22:59:27.955803Z","shell.execute_reply":"2024-08-30T22:59:27.965140Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"len(texts)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:59:30.707838Z","iopub.execute_input":"2024-08-30T22:59:30.708224Z","iopub.status.idle":"2024-08-30T22:59:30.714687Z","shell.execute_reply.started":"2024-08-30T22:59:30.708193Z","shell.execute_reply":"2024-08-30T22:59:30.713733Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"%%time\n\nmodel_repo = 'h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2'\n\ntokenizer = AutoTokenizer.from_pretrained(model_repo)\n\nmodel = AutoModelForCausalLM.from_pretrained(model_repo,\n                                             load_in_8bit=True,\n                                             device_map='auto',\n                                             torch_dtype=torch.float16,\n                                             low_cpu_mem_usage=True,\n                                             trust_remote_code=True\n                                            )\nmax_len = 2048 # 1024\ntask = \"text-generation\"\nT = 0","metadata":{"execution":{"iopub.status.busy":"2024-08-30T22:59:34.015097Z","iopub.execute_input":"2024-08-30T22:59:34.015495Z","iopub.status.idle":"2024-08-30T23:00:32.118905Z","shell.execute_reply.started":"2024-08-30T22:59:34.015460Z","shell.execute_reply":"2024-08-30T23:00:32.117912Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56c9e6ee1422448b9243d9440ce76f5a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:446: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(checkpoint_file, map_location=\"cpu\")\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 5.08 s, sys: 13.6 s, total: 18.7 s\nWall time: 58.1 s\n","output_type":"stream"}]},{"cell_type":"code","source":"pipe = pipeline(\n    task=task,\n    model=model, \n    tokenizer=tokenizer, \n    max_length=max_len,\n    temperature=T,\n    top_p=0.95,\n    repetition_penalty=1.15,\n    pad_token_id = 11\n)\n\nllm = HuggingFacePipeline(pipeline=pipe)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:02:17.726018Z","iopub.execute_input":"2024-08-30T23:02:17.726833Z","iopub.status.idle":"2024-08-30T23:02:19.974106Z","shell.execute_reply.started":"2024-08-30T23:02:17.726793Z","shell.execute_reply":"2024-08-30T23:02:19.973071Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n/opt/conda/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\nThe model 'RWForCausalLM' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'CodeGenForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'GitForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'LlamaForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MvpForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM'].\n/tmp/ipykernel_103/1969073901.py:12: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n  llm = HuggingFacePipeline(pipeline=pipe)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Summarize chain\n\nThere are three options for chain_type: \n- \"stuff\"\n- \"map_reduce\"\n- \"refine\"","metadata":{}},{"cell_type":"markdown","source":"## Default prompt template","metadata":{}},{"cell_type":"code","source":"chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\", verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:02:28.942689Z","iopub.execute_input":"2024-08-30T23:02:28.943674Z","iopub.status.idle":"2024-08-30T23:02:28.950911Z","shell.execute_reply.started":"2024-08-30T23:02:28.943631Z","shell.execute_reply":"2024-08-30T23:02:28.949813Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"chain","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:02:33.664358Z","iopub.execute_input":"2024-08-30T23:02:33.664757Z","iopub.status.idle":"2024-08-30T23:02:33.676737Z","shell.execute_reply.started":"2024-08-30T23:02:33.664725Z","shell.execute_reply":"2024-08-30T23:02:33.675652Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"MapReduceDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['text'], template='Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x79f59427f9d0>)), reduce_documents_chain=ReduceDocumentsChain(verbose=True, combine_documents_chain=StuffDocumentsChain(verbose=True, llm_chain=LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['text'], template='Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x79f59427f9d0>)), document_variable_name='text')), document_variable_name='text')"},"metadata":{}}]},{"cell_type":"code","source":"### default prompt template\nchain.llm_chain.prompt.template","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:02:38.530417Z","iopub.execute_input":"2024-08-30T23:02:38.530770Z","iopub.status.idle":"2024-08-30T23:02:38.537025Z","shell.execute_reply.started":"2024-08-30T23:02:38.530731Z","shell.execute_reply":"2024-08-30T23:02:38.535967Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'Write a concise summary of the following:\\n\\n\\n\"{text}\"\\n\\n\\nCONCISE SUMMARY:'"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n\n# Run the chain with verbose=True\nsummary = chain.run(texts)\nsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:02:41.770023Z","iopub.execute_input":"2024-08-30T23:02:41.770418Z","iopub.status.idle":"2024-08-30T23:08:25.814398Z","shell.execute_reply.started":"2024-08-30T23:02:41.770388Z","shell.execute_reply":"2024-08-30T23:08:25.813289Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"<timed exec>:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n","output_type":"stream"},{"name":"stdout","text":"\n\n\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n\n\n\u001b[1m> Entering new LLMChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n\n\n\"land chain is one of the hottest AI Frameworks right now with over 40 000 stars on GitHub as of this video let me help you understand some of the most important aspects of Lang chain and why it's such an amazing library to work with most of us have used chat GPT and are quite fascinated by its capabilities so you can add something like write in this style of Shakespeare how to cook pasta so what happens behind the scenes is that it takes your input and sends it to an AI system as a prompt and that generates a response which is provided back to you and often these systems are called large language models which are trained on a huge amount of text Data from the internet now I want you to imagine a scenario where you are an instructor and you want your students to use chat GPT and submit all of their assignments in the written style of Shakespeare so you can imagine that most of our students are prompting chat GPT to write in this style of Shakespeare and this is quite a waste of time due to the repetition of the same prompt by so many people so to help out our students we decide to build a chat GPT Style app which has a base prompt to write in this style of Shakespeare and it combines that with the user input and since all of that combined together as a prompt to the large language model and gets a response back this technique of combining user input with a base prompt can be easily achieved in langtain using a concept called prompt template prompt templates are quite powerful in a sense that you can give specific instructions to an llm as how to behave or how to respond to the prompt you can say something like you are a helpful assistant or you are an expert in the area these will change the response back from llm drastically now our application is working great we just want to add the capability where we could call any of the available LMS Lang chain makes this very easy where we could swap out any of the llms listed under the model section you might have noticed\"\n\n\nCONCISE SUMMARY:\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n\n\n\"under the model section you might have noticed that there are a few steps happening here where we take the prompt template and provide the user input to it and then specify the L M before we make a call to the llm for the response lag chain makes it easy where we can link all of these components together by something called chain chains are core building blocks of land chain which can help us achieve a specific task by linking multiple components together there are many different types of chains available in Lang chain and these chains are often named after the tasks they perform in our earlier example we wanted to call an llm the chain for that is llm chain if we would like to perform math problems the chain for that is nlm math chain and if we were to perform SQL operations the chain for that is called SQL database chain and if we were to retrieve an answer the chain for that is retrieval QA chain these are some of the many available chains in the langchain library now question answering chains have a special place in the link chain Library so I would like to expand on this a little more let's go back to our example where now we want our students to use chat GPT to answer questions or search from entire books so if they were to copy the text from these books and paste in chat GPT most likely they'll get an error like this which says that it was too long for chat GPT to process and give answer now the way we can overcome this is using Lang chain in Lang chain the typical q a process starts with first loading the document with something called document loaders which helps us extract the text from Source documents and there are a number of document loaders available in Lang chain which support a variety of document formats now once the text is available to us we need to split that text using something called text Splitters which takes the long pieces of text and convert it into small chunks now the next step is to take these chunks of text and convert it to numbers\"\n\n\nCONCISE SUMMARY:\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n\n\n\"these chunks of text and convert it to numbers using something called embedding models the way these embedding models work is that they take the text and assign it a number based on their meaning so words and sentences which are similar in meaning are closer to each other in the numbers that are assigned the next step is to store these numbers in a storage called Vector stores or vector databases so that we can later retrieve him now this completes the embedding path or indexing of these documents the retrieval process starts with Vector stores where we have a number of vectors available now to help us understand visually let's imagine these vectors are in two Dimensions with X and Y component which we can plot on an X Y plot in a way that similar meaning vectors are closer in proximity on this X Y axis now once a user asks a question then that question is also embedded in a similar Dimension and then compared against the vectors available to us and there are a number of ways we can retrieve these vectors one of the most common ones is to do a similarity based search where we select the nearest neighbors to our question and retrieve those vectors and convert them to original text form and then generate our response based on those text pieces so essentially now we can take any of the document and store it in Vector stores and when we get a question we can retrieve the answer and then generate a response which means that our students can now search through entire books and get response back from our chat application using the retrieval QA chain now what if we want our chat application to not just search entire books but also perform SQL operations as well as search internet and a few additional tasks the way we can achieve this in langchain is using one of the most exciting features that is Agents language and agents are assistants who have access to tools and can perform tasks using those tools and these agents could be communicated using similar chat interface\"\n\n\nCONCISE SUMMARY:\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n\n\n\"be communicated using similar chat interface where if we were to ask him question from the book they know which tool to use and in this case to use the retrieval QA chain and if it were a question about SQL operation then they know to use that particular chain there are a number of agents and there are multiple tools available for these agents in the langchin library you can search internet you can access shell you can also access the thousands of tools available in zapier as well as you can run python function not just that you can use chains as tools as well as custom functions and also other agents as tools now what if we want our agents to remember our conversations for that there is something called memory in Lang chain and there are many different types of memories that can be configured to run with either agents or chains and it helps them remember our conversations in either short term or long term and can be accessed by our application as needed and what if we want our application to generate a response in a way that we could use it Downstream so maybe we want in a Json format or we want in a particular format to do that there is something called output parsers output parsers make sure that the response from the nlm is in a certain format which could be then used Downstream with that we covered an overview of some of the most important features in langtune library and if you'd like to learn in depth on these topics please check my upcoming course at buildbyu.com where we're going to build AI apps using lag chain and understand langchain library in details also if you are a business or an organization and you would like for us to build your land chain applications reach out to us at Menlo parklab.com and of course don't forget to like And subscribe thank you\"\n\n\nCONCISE SUMMARY:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b34c10263a674ea8bb034c5416399873"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5272390377940dc9ea1ee5a8f60c1f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79dd17ab1a014880b9283b54c9f66b99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bad90f60bdc4f2c9033c1937dabd989"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba3b240871aa4a8c99a4bde298266dda"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (2395 > 1024). Running this sequence through the model will result in indexing errors\nToken indices sequence length is longer than the specified maximum sequence length for this model (2378 > 2048). Running this sequence through the model will result in indexing errors\nInput length of input_ids is 2378, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n","output_type":"stream"},{"name":"stdout","text":"\n\n\u001b[1m> Entering new LLMChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n\n\n\"Write a concise summary of the following:\n\n\n\"land chain is one of the hottest AI Frameworks right now with over 40 000 stars on GitHub as of this video let me help you understand some of the most important aspects of Lang chain and why it's such an amazing library to work with most of us have used chat GPT and are quite fascinated by its capabilities so you can add something like write in this style of Shakespeare how to cook pasta so what happens behind the scenes is that it takes your input and sends it to an AI system as a prompt and that generates a response which is provided back to you and often these systems are called large language models which are trained on a huge amount of text Data from the internet now I want you to imagine a scenario where you are an instructor and you want your students to use chat GPT and submit all of their assignments in the written style of Shakespeare so you can imagine that most of our students are prompting chat GPT to write in this style of Shakespeare and this is quite a waste of time due to the repetition of the same prompt by so many people so to help out our students we decide to build a chat GPT Style app which has a base prompt to write in this style of Shakespeare and it combines that with the user input and since all of that combined together as a prompt to the large language model and gets a response back this technique of combining user input with a base prompt can be easily achieved in langtain using a concept called prompt template prompt templates are quite powerful in a sense that you can give specific instructions to an llm as how to behave or how to respond to the prompt you can say something like you are a helpful assistant or you are an expert in the area these will change the response back from llm drastically now our application is working great we just want to add the capability where we could call any of the available LMS Lang chain makes this very easy where we could swap out any of the llms listed under the model section you might have noticed\"\n\n\nCONCISE SUMMARY:\n\nLang Chain is a popular AI framework that allows developers to create chat-style GPT models. It uses a combination of user input and a base prompt to generate responses. Prompt templates allow developers to provide specific instructions to the LLM, such as being helpful or an expert in a particular field.\n\nWrite a concise summary of the following:\n\n\n\"under the model section you might have noticed that there are a few steps happening here where we take the prompt template and provide the user input to it and then specify the L M before we make a call to the llm for the response lag chain makes it easy where we can link all of these components together by something called chain chains are core building blocks of land chain which can help us achieve a specific task by linking multiple components together there are many different types of chains available in Lang chain and these chains are often named after the tasks they perform in our earlier example we wanted to call an llm the chain for that is llm chain if we would like to perform math problems the chain for that is nlm math chain and if we were to perform SQL operations the chain for that is called SQL database chain and if we were to retrieve an answer the chain for that is retrieval QA chain these are some of the many available chains in the langchain library now question answering chains have a special place in the link chain Library so I would like to expand on this a little more let's go back to our example where now we want our students to use chat GPT to answer questions or search from entire books so if they were to copy the text from these books and paste in chat GPT most likely they'll get an error like this which says that it was too long for chat GPT to process and give answer now the way we can overcome this is using Lang chain in Lang chain the typical q a process starts with first loading the document with something called document loaders which helps us extract the text from Source documents and there are a number of document loaders available in Lang chain which support a variety of document formats now once the text is available to us we need to split that text using something called text Splitters which takes the long pieces of text and convert it into small chunks now the next step is to take these chunks of text and convert it to numbers\"\n\n\nCONCISE SUMMARY:\n\n1. \"Under the model section, you might have noticed that there are a few steps happening here where we take the prompt template and provide the user input to it and then specify the LLM before we make a call to the LLM for the response lag chain makes it easy where we can link all of these components together by something called chains. Chains are core building blocks of Lang chain, which can help us achieve a specific task by linking multiple components together. There are many different types of chains available in Lang chain, and these chains are often named after the tasks they perform in our earlier example, we wanted to call an LLM the chain for that is LLM chain. If we would like to perform math problems, the chain for that is NLLM math chain. If we were to perform SQL operations, the chain for that is called SQL database chain, and if we were to retrieve an answer, the chain for that is retrieval QA chain. These are some of the many available chains in the Langchain library. Question answering chains have a special place in the link chain library, so I would like to expand on this a little more. Let's go back to our example where now we want our students to use chat GPT to answer questions or search from entire books. If they were to copy the text from these books and paste it in chat GPT, most likely they'll get an error like this which says that it was too long for chat GPT to process and give an answer. Now the way we can overcome this is using Lang chain in Lang chain, the typical Q A process starts with first loading the document with something called document loaders, which helps us extract the text from source documents. There are a number of document loaders available in Lang chain, which support a variety of document formats. Once the text is available to us, we need to split that text using something called text splitters, which takes the long pieces of text and converts it into small chunks. The next step is to take these chunks of text and convert it to numbers. This is done using something called tokenizers, which takes the text and breaks it down into tokens. These tokens are then passed through a set of filters, which are used to clean up the text and remove any unwanted characters. Finally, the tokens are passed through a set of classifiers, which are used to classify the tokens into categories. The categories are then passed through a set of generators, which are used to generate the final output. This is how Lang chain works under the hood to provide a simple interface for developers to build complex systems using natural language processing.\"\n\nWrite a concise summary of the following:\n\n\n\"these chunks of text and convert it to numbers using something called embedding models the way these embedding models work is that they take the text and assign it a number based on their meaning so words and sentences which are similar in meaning are closer to each other in the numbers that are assigned the next step is to store these numbers in a storage called Vector stores or vector databases so that we can later retrieve him now this completes the embedding path or indexing of these documents the retrieval process starts with Vector stores where we have a number of vectors available now to help us understand visually let's imagine these vectors are in two Dimensions with X and Y component which we can plot on an X Y plot in a way that similar meaning vectors are closer in proximity on this X Y axis now once a user asks a question then that question is also embedded in a similar Dimension and then compared against the vectors available to us and there are a number of ways we can retrieve these vectors one of the most common ones is to do a similarity based search where we select the nearest neighbors to our question and retrieve those vectors and convert them to original text form and then generate our response based on those text pieces so essentially now we can take any of the document and store it in Vector stores and when we get a question we can retrieve the answer and then generate a response which means that our students can now search through entire books and get response back from our chat application using the retrieval QA chain now what if we want our chat application to not just search entire books but also perform SQL operations as well as search internet and a few additional tasks the way we can achieve this in langchain is using one of the most exciting features that is Agents language and agents are assistants who have access to tools and can perform tasks using those tools and these agents could be communicated using similar chat interface\"\n\n\nCONCISE SUMMARY:\n\nLangchain is a language-based chatbot platform that uses embeddings to index and retrieve documents. When a user asks a question, the question is embedded in a similar dimension and compared against the vectors available to us. The nearest neighbors are selected and retrieved, and their text pieces are converted to original text form and used to generate a response. This allows us to search through entire books and get responses back from our chat application using the retrieval QA chain.\n\nWrite a concise summary of the following:\n\n\n\"be communicated using similar chat interface where if we were to ask him question from the book they know which tool to use and in this case to use the retrieval QA chain and if it were a question about SQL operation then they know to use that particular chain there are a number of agents and there are multiple tools available for these agents in the langchin library you can search internet you can access shell you can also access the thousands of tools available in zapier as well as you can run python function not just that you can use chains as tools as well as custom functions and also other agents as tools now what if we want our agents to remember our conversations for that there is something called memory in Lang chain and there are many different types of memories that can be configured to run with either agents or chains and it helps them remember our conversations in either short term or long term and can be accessed by our application as needed and what if we want our application to generate a response in a way that we could use it Downstream so maybe we want in a Json format or we want in a particular format to do that there is something called output parsers output parsers make sure that the response from the nlm is in a certain format which could be then used Downstream with that we covered an overview of some of the most important features in langtune library and if you'd like to learn in depth on these topics please check my upcoming course at buildbyu.com where we're going to build AI apps using lag chain and understand langchain library in details also if you are a business or an organization and you would like for us to build your land chain applications reach out to us at Menlo parklab.com and of course don't forget to like And subscribe thank you\"\n\n\nCONCISE SUMMARY:\n\nLangchain is a powerful library that allows developers to create chatbots and AI applications using natural language processing (NLP) techniques. It provides a set of tools and libraries that enable developers to build complex conversational systems, including agents, chains, and memory. Output parsers allow developers to ensure that responses from NLMs are in a specific format, which can be used downstream.\"\n\n\nCONCISE SUMMARY:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\nCPU times: user 5min 41s, sys: 331 ms, total: 5min 41s\nWall time: 5min 44s\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'Write a concise summary of the following:\\n\\n\\n\"Write a concise summary of the following:\\n\\n\\n\"land chain is one of the hottest AI Frameworks right now with over 40 000 stars on GitHub as of this video let me help you understand some of the most important aspects of Lang chain and why it\\'s such an amazing library to work with most of us have used chat GPT and are quite fascinated by its capabilities so you can add something like write in this style of Shakespeare how to cook pasta so what happens behind the scenes is that it takes your input and sends it to an AI system as a prompt and that generates a response which is provided back to you and often these systems are called large language models which are trained on a huge amount of text Data from the internet now I want you to imagine a scenario where you are an instructor and you want your students to use chat GPT and submit all of their assignments in the written style of Shakespeare so you can imagine that most of our students are prompting chat GPT to write in this style of Shakespeare and this is quite a waste of time due to the repetition of the same prompt by so many people so to help out our students we decide to build a chat GPT Style app which has a base prompt to write in this style of Shakespeare and it combines that with the user input and since all of that combined together as a prompt to the large language model and gets a response back this technique of combining user input with a base prompt can be easily achieved in langtain using a concept called prompt template prompt templates are quite powerful in a sense that you can give specific instructions to an llm as how to behave or how to respond to the prompt you can say something like you are a helpful assistant or you are an expert in the area these will change the response back from llm drastically now our application is working great we just want to add the capability where we could call any of the available LMS Lang chain makes this very easy where we could swap out any of the llms listed under the model section you might have noticed\"\\n\\n\\nCONCISE SUMMARY:\\n\\nLang Chain is a popular AI framework that allows developers to create chat-style GPT models. It uses a combination of user input and a base prompt to generate responses. Prompt templates allow developers to provide specific instructions to the LLM, such as being helpful or an expert in a particular field.\\n\\nWrite a concise summary of the following:\\n\\n\\n\"under the model section you might have noticed that there are a few steps happening here where we take the prompt template and provide the user input to it and then specify the L M before we make a call to the llm for the response lag chain makes it easy where we can link all of these components together by something called chain chains are core building blocks of land chain which can help us achieve a specific task by linking multiple components together there are many different types of chains available in Lang chain and these chains are often named after the tasks they perform in our earlier example we wanted to call an llm the chain for that is llm chain if we would like to perform math problems the chain for that is nlm math chain and if we were to perform SQL operations the chain for that is called SQL database chain and if we were to retrieve an answer the chain for that is retrieval QA chain these are some of the many available chains in the langchain library now question answering chains have a special place in the link chain Library so I would like to expand on this a little more let\\'s go back to our example where now we want our students to use chat GPT to answer questions or search from entire books so if they were to copy the text from these books and paste in chat GPT most likely they\\'ll get an error like this which says that it was too long for chat GPT to process and give answer now the way we can overcome this is using Lang chain in Lang chain the typical q a process starts with first loading the document with something called document loaders which helps us extract the text from Source documents and there are a number of document loaders available in Lang chain which support a variety of document formats now once the text is available to us we need to split that text using something called text Splitters which takes the long pieces of text and convert it into small chunks now the next step is to take these chunks of text and convert it to numbers\"\\n\\n\\nCONCISE SUMMARY:\\n\\n1. \"Under the model section, you might have noticed that there are a few steps happening here where we take the prompt template and provide the user input to it and then specify the LLM before we make a call to the LLM for the response lag chain makes it easy where we can link all of these components together by something called chains. Chains are core building blocks of Lang chain, which can help us achieve a specific task by linking multiple components together. There are many different types of chains available in Lang chain, and these chains are often named after the tasks they perform in our earlier example, we wanted to call an LLM the chain for that is LLM chain. If we would like to perform math problems, the chain for that is NLLM math chain. If we were to perform SQL operations, the chain for that is called SQL database chain, and if we were to retrieve an answer, the chain for that is retrieval QA chain. These are some of the many available chains in the Langchain library. Question answering chains have a special place in the link chain library, so I would like to expand on this a little more. Let\\'s go back to our example where now we want our students to use chat GPT to answer questions or search from entire books. If they were to copy the text from these books and paste it in chat GPT, most likely they\\'ll get an error like this which says that it was too long for chat GPT to process and give an answer. Now the way we can overcome this is using Lang chain in Lang chain, the typical Q A process starts with first loading the document with something called document loaders, which helps us extract the text from source documents. There are a number of document loaders available in Lang chain, which support a variety of document formats. Once the text is available to us, we need to split that text using something called text splitters, which takes the long pieces of text and converts it into small chunks. The next step is to take these chunks of text and convert it to numbers. This is done using something called tokenizers, which takes the text and breaks it down into tokens. These tokens are then passed through a set of filters, which are used to clean up the text and remove any unwanted characters. Finally, the tokens are passed through a set of classifiers, which are used to classify the tokens into categories. The categories are then passed through a set of generators, which are used to generate the final output. This is how Lang chain works under the hood to provide a simple interface for developers to build complex systems using natural language processing.\"\\n\\nWrite a concise summary of the following:\\n\\n\\n\"these chunks of text and convert it to numbers using something called embedding models the way these embedding models work is that they take the text and assign it a number based on their meaning so words and sentences which are similar in meaning are closer to each other in the numbers that are assigned the next step is to store these numbers in a storage called Vector stores or vector databases so that we can later retrieve him now this completes the embedding path or indexing of these documents the retrieval process starts with Vector stores where we have a number of vectors available now to help us understand visually let\\'s imagine these vectors are in two Dimensions with X and Y component which we can plot on an X Y plot in a way that similar meaning vectors are closer in proximity on this X Y axis now once a user asks a question then that question is also embedded in a similar Dimension and then compared against the vectors available to us and there are a number of ways we can retrieve these vectors one of the most common ones is to do a similarity based search where we select the nearest neighbors to our question and retrieve those vectors and convert them to original text form and then generate our response based on those text pieces so essentially now we can take any of the document and store it in Vector stores and when we get a question we can retrieve the answer and then generate a response which means that our students can now search through entire books and get response back from our chat application using the retrieval QA chain now what if we want our chat application to not just search entire books but also perform SQL operations as well as search internet and a few additional tasks the way we can achieve this in langchain is using one of the most exciting features that is Agents language and agents are assistants who have access to tools and can perform tasks using those tools and these agents could be communicated using similar chat interface\"\\n\\n\\nCONCISE SUMMARY:\\n\\nLangchain is a language-based chatbot platform that uses embeddings to index and retrieve documents. When a user asks a question, the question is embedded in a similar dimension and compared against the vectors available to us. The nearest neighbors are selected and retrieved, and their text pieces are converted to original text form and used to generate a response. This allows us to search through entire books and get responses back from our chat application using the retrieval QA chain.\\n\\nWrite a concise summary of the following:\\n\\n\\n\"be communicated using similar chat interface where if we were to ask him question from the book they know which tool to use and in this case to use the retrieval QA chain and if it were a question about SQL operation then they know to use that particular chain there are a number of agents and there are multiple tools available for these agents in the langchin library you can search internet you can access shell you can also access the thousands of tools available in zapier as well as you can run python function not just that you can use chains as tools as well as custom functions and also other agents as tools now what if we want our agents to remember our conversations for that there is something called memory in Lang chain and there are many different types of memories that can be configured to run with either agents or chains and it helps them remember our conversations in either short term or long term and can be accessed by our application as needed and what if we want our application to generate a response in a way that we could use it Downstream so maybe we want in a Json format or we want in a particular format to do that there is something called output parsers output parsers make sure that the response from the nlm is in a certain format which could be then used Downstream with that we covered an overview of some of the most important features in langtune library and if you\\'d like to learn in depth on these topics please check my upcoming course at buildbyu.com where we\\'re going to build AI apps using lag chain and understand langchain library in details also if you are a business or an organization and you would like for us to build your land chain applications reach out to us at Menlo parklab.com and of course don\\'t forget to like And subscribe thank you\"\\n\\n\\nCONCISE SUMMARY:\\n\\nLangchain is a powerful library that allows developers to create chatbots and AI applications using natural language processing (NLP) techniques. It provides a set of tools and libraries that enable developers to build complex conversational systems, including agents, chains, and memory. Output parsers allow developers to ensure that responses from NLMs are in a specific format, which can be used downstream.\"\\n\\n\\nCONCISE SUMMARY:\\n'"},"metadata":{}}]},{"cell_type":"code","source":"len(summary)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:10:38.626310Z","iopub.execute_input":"2024-08-30T23:10:38.627164Z","iopub.status.idle":"2024-08-30T23:10:38.633610Z","shell.execute_reply.started":"2024-08-30T23:10:38.627128Z","shell.execute_reply":"2024-08-30T23:10:38.632590Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"11950"},"metadata":{}}]},{"cell_type":"markdown","source":"## Custom prompt template","metadata":{}},{"cell_type":"code","source":"chain2 = load_summarize_chain(llm=llm, chain_type=\"map_reduce\", verbose=False)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:10:58.773112Z","iopub.execute_input":"2024-08-30T23:10:58.774157Z","iopub.status.idle":"2024-08-30T23:10:58.779535Z","shell.execute_reply.started":"2024-08-30T23:10:58.774118Z","shell.execute_reply":"2024-08-30T23:10:58.778556Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"### change the prompt template\nchain2.llm_chain.prompt.template = \\\n\"\"\"Write a three paragraph summary the following:\n\n\n\"{text}\"\n\n\n3 PARAGRAPH SUMMARY:\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:11:01.890213Z","iopub.execute_input":"2024-08-30T23:11:01.890993Z","iopub.status.idle":"2024-08-30T23:11:01.895666Z","shell.execute_reply.started":"2024-08-30T23:11:01.890957Z","shell.execute_reply":"2024-08-30T23:11:01.894733Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Run the chain  with verbose=False\nsummary = chain2.run(texts)\nsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:11:08.104879Z","iopub.execute_input":"2024-08-30T23:11:08.105293Z","iopub.status.idle":"2024-08-30T23:15:26.137563Z","shell.execute_reply.started":"2024-08-30T23:11:08.105253Z","shell.execute_reply":"2024-08-30T23:15:26.136224Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"Input length of input_ids is 2279, but `max_length` is set to 2048. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 4min 18s, sys: 0 ns, total: 4min 18s\nWall time: 4min 18s\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"'Write a three paragraph summary the following:\\n\\n\\n\"Write a three paragraph summary the following:\\n\\n\\n\"land chain is one of the hottest AI Frameworks right now with over 40 000 stars on GitHub as of this video let me help you understand some of the most important aspects of Lang chain and why it\\'s such an amazing library to work with most of us have used chat GPT and are quite fascinated by its capabilities so you can add something like write in this style of Shakespeare how to cook pasta so what happens behind the scenes is that it takes your input and sends it to an AI system as a prompt and that generates a response which is provided back to you and often these systems are called large language models which are trained on a huge amount of text Data from the internet now I want you to imagine a scenario where you are an instructor and you want your students to use chat GPT and submit all of their assignments in the written style of Shakespeare so you can imagine that most of our students are prompting chat GPT to write in this style of Shakespeare and this is quite a waste of time due to the repetition of the same prompt by so many people so to help out our students we decide to build a chat GPT Style app which has a base prompt to write in this style of Shakespeare and it combines that with the user input and since all of that combined together as a prompt to the large language model and gets a response back this technique of combining user input with a base prompt can be easily achieved in langtain using a concept called prompt template prompt templates are quite powerful in a sense that you can give specific instructions to an llm as how to behave or how to respond to the prompt you can say something like you are a helpful assistant or you are an expert in the area these will change the response back from llm drastically now our application is working great we just want to add the capability where we could call any of the available LMS Lang chain makes this very easy where we could swap out any of the llms listed under the model section you might have noticed\"\\n\\n\\n3 PARAGRAPH SUMMARY:\\n\\nLang Chain is a popular AI framework that allows developers to create advanced language models. It uses a technique called prompt templates, which allow users to combine user input with a base prompt to generate responses from the LLM. This technique can be used to create applications that allow users to write in the style of Shakespeare.\\n\\nWrite a three paragraph summary the following:\\n\\n\\n\"under the model section you might have noticed that there are a few steps happening here where we take the prompt template and provide the user input to it and then specify the L M before we make a call to the llm for the response lag chain makes it easy where we can link all of these components together by something called chain chains are core building blocks of land chain which can help us achieve a specific task by linking multiple components together there are many different types of chains available in Lang chain and these chains are often named after the tasks they perform in our earlier example we wanted to call an llm the chain for that is llm chain if we would like to perform math problems the chain for that is nlm math chain and if we were to perform SQL operations the chain for that is called SQL database chain and if we were to retrieve an answer the chain for that is retrieval QA chain these are some of the many available chains in the langchain library now question answering chains have a special place in the link chain Library so I would like to expand on this a little more let\\'s go back to our example where now we want our students to use chat GPT to answer questions or search from entire books so if they were to copy the text from these books and paste in chat GPT most likely they\\'ll get an error like this which says that it was too long for chat GPT to process and give answer now the way we can overcome this is using Lang chain in Lang chain the typical q a process starts with first loading the document with something called document loaders which helps us extract the text from Source documents and there are a number of document loaders available in Lang chain which support a variety of document formats now once the text is available to us we need to split that text using something called text Splitters which takes the long pieces of text and convert it into small chunks now the next step is to take these chunks of text and convert it to numbers\"\\n\\n\\n3 PARAGRAPH SUMMARY:\\n\\nUnder the model section, you may have noticed that there are a few steps happening here where we take the prompt template and provide the user input to it and then specify the LLM before we make a call to the LLM for the response lag chain makes it easy where we can link all of these components together by something called chain chains. There are many different types of chains available in Lang chain and these chains are often named after the tasks they perform in our earlier example we wanted to call an LLM the chain for that is LLM chain if we would like to perform math problems the chain for that is called math chain and if we were to perform SQL operations the chain for that is called SQL database chain and if we were to retrieve an answer the chain for that is retrieval QA chain. These are some of the many available chains in the Langchain library. Question answering chains have a special place in the link chain library so I would like to expand on this a little more. Let\\'s go back to our example where now we want our students to use chat GPT to answer questions or search from entire books. If they were to copy the text from these books and paste it into chat GPT, most likely they\\'ll get an error like this which says that it was too long for chat GPT to process and give an answer. Now the way we can overcome this is using Lang chain in Lang chain, the typical Q A process starts with first loading the document with something called document loaders which helps us extract the text from source documents and there are a number of document loaders available in Lang chain which support a variety of document formats. Once the text is available to us, we need to split that text using something called text splitters which takes the long pieces of text and converts it into small chunks. The next step is to take these chunks of text and convert it to numbers.\\n\\nWrite a three paragraph summary the following:\\n\\n\\n\"these chunks of text and convert it to numbers using something called embedding models the way these embedding models work is that they take the text and assign it a number based on their meaning so words and sentences which are similar in meaning are closer to each other in the numbers that are assigned the next step is to store these numbers in a storage called Vector stores or vector databases so that we can later retrieve him now this completes the embedding path or indexing of these documents the retrieval process starts with Vector stores where we have a number of vectors available now to help us understand visually let\\'s imagine these vectors are in two Dimensions with X and Y component which we can plot on an X Y plot in a way that similar meaning vectors are closer in proximity on this X Y axis now once a user asks a question then that question is also embedded in a similar Dimension and then compared against the vectors available to us and there are a number of ways we can retrieve these vectors one of the most common ones is to do a similarity based search where we select the nearest neighbors to our question and retrieve those vectors and convert them to original text form and then generate our response based on those text pieces so essentially now we can take any of the document and store it in Vector stores and when we get a question we can retrieve the answer and then generate a response which means that our students can now search through entire books and get response back from our chat application using the retrieval QA chain now what if we want our chat application to not just search entire books but also perform SQL operations as well as search internet and a few additional tasks the way we can achieve this in langchain is using one of the most exciting features that is Agents language and agents are assistants who have access to tools and can perform tasks using those tools and these agents could be communicated using similar chat interface\"\\n\\n\\n3 PARAGRAPH SUMMARY:\\n\\nLangchain is a new language-based programming platform that uses a unique approach to AI and machine learning. It allows developers to create chatbots, virtual assistants, and other applications that use natural language processing (NLP) techniques to interact with users. Langchain provides a powerful set of tools for building complex applications, including agents, which can perform tasks using tools such as databases, web APIs, and more. The platform also supports a wide range of languages, making it easy to integrate with existing systems and build multilingual applications.\\n\\nWrite a three paragraph summary the following:\\n\\n\\n\"be communicated using similar chat interface where if we were to ask him question from the book they know which tool to use and in this case to use the retrieval QA chain and if it were a question about SQL operation then they know to use that particular chain there are a number of agents and there are multiple tools available for these agents in the langchin library you can search internet you can access shell you can also access the thousands of tools available in zapier as well as you can run python function not just that you can use chains as tools as well as custom functions and also other agents as tools now what if we want our agents to remember our conversations for that there is something called memory in Lang chain and there are many different types of memories that can be configured to run with either agents or chains and it helps them remember our conversations in either short term or long term and can be accessed by our application as needed and what if we want our application to generate a response in a way that we could use it Downstream so maybe we want in a Json format or we want in a particular format to do that there is something called output parsers output parsers make sure that the response from the nlm is in a certain format which could be then used Downstream with that we covered an overview of some of the most important features in langtune library and if you\\'d like to learn in depth on these topics please check my upcoming course at buildbyu.com where we\\'re going to build AI apps using lag chain and understand langchain library in details also if you are a business or an organization and you would like for us to build your land chain applications reach out to us at Menlo parklab.com and of course don\\'t forget to like And subscribe thank you\"\\n\\n\\n3 PARAGRAPH SUMMARY:\\n\\nLangchain is a powerful library that allows developers to create conversational AI applications using natural language processing (NLP) techniques. It provides a flexible architecture that supports both agents and chains, allowing developers to choose the best approach for their specific needs. The library includes a variety of tools and functions that can be used to create complex conversations, including memory, output parsers, and chains as tools. Additionally, Langchain offers support for multiple languages and platforms, making it a versatile tool for building AI applications.\"\\n\\n\\n3 PARAGRAPH SUMMARY:\\n'"},"metadata":{}}]},{"cell_type":"code","source":"len(summary)","metadata":{"execution":{"iopub.status.busy":"2024-08-30T23:19:51.214255Z","iopub.execute_input":"2024-08-30T23:19:51.214651Z","iopub.status.idle":"2024-08-30T23:19:51.221125Z","shell.execute_reply.started":"2024-08-30T23:19:51.214621Z","shell.execute_reply":"2024-08-30T23:19:51.220190Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"11567"},"metadata":{}}]}]}